# ğŸš€ Advanced Path Planning Algorithms for Intelligent Mobile Robots

## ğŸ“Œ Overview
This repository contains implementations of various **advanced path-planning algorithms** used in autonomous mobile robots. These algorithms are widely applied in **robotics, AI, and autonomous navigation systems**. 

The repository includes implementations of:
- **A\***, **D\***, **Hybrid DQN-A\***, **RRT\***, and **Theta\*** algorithms.
- Efficient solutions for **navigation in dynamic and static environments**.

---

## âœ¨ Features
âœ” **A\* Algorithm** - Implements the classical A\* search and bidirectional variant for optimal path planning.  
âœ” **D\* Algorithm** - A dynamic path planning algorithm that adapts to changing environments.  
âœ” **Hybrid DQN-A\*** - A hybrid approach combining Deep Q-Network (DQN) with A\* for intelligent decision-making.  
âœ” **RRT\* Algorithm** - Rapidly-exploring Random Tree (RRT\*) for sampling-based path planning.  
âœ” **Theta\* Algorithm** - An optimized variant of A\* allowing any-angle path planning.  

---

## ğŸ“‚ Directory Structure
```plaintext
ğŸ“¦ Advanced_Path_Planning
â”œâ”€â”€ ğŸ“‚ A_Star
â”‚   â”œâ”€â”€ ğŸ“„ README.md
â”‚   â”œâ”€â”€ ğŸ“„ a_star_algorithm.py
â”‚   â”œâ”€â”€ ğŸ“„ a_star_bidirectional_algorithm.py
â”‚
â”œâ”€â”€ ğŸ“‚ D_Star
â”‚   â”œâ”€â”€ ğŸ“„ README.md
â”‚   â”œâ”€â”€ ğŸ“„ d_star.py
â”‚
â”œâ”€â”€ ğŸ“‚ Hybrid_DQN_A_Star
â”‚   â”œâ”€â”€ ğŸ“„ README.md
â”‚   â”œâ”€â”€ ğŸ“„ hybrid_dqn_a_star_algorithm.py
â”‚
â”œâ”€â”€ ğŸ“‚ RRT_Star
â”‚   â”œâ”€â”€ ğŸ“„ README.md
â”‚   â”œâ”€â”€ ğŸ“„ rrt_star_algorithm.py
â”‚
â”œâ”€â”€ ğŸ“‚ Theta_Star
â”‚   â”œâ”€â”€ ğŸ“„ README.md
â”‚   â”œâ”€â”€ ğŸ“„ theta_star_algorithm.py
â”‚
â”œâ”€â”€ ğŸ“‚ media
â”‚   â”œâ”€â”€ ğŸ“¹ astar.gif
â”‚   â”œâ”€â”€ ğŸ“¹ astar_bidirectional.gif
â”‚   â”œâ”€â”€ ğŸ“¹ dstar.gif
â”‚   â”œâ”€â”€ ğŸ“¹ dqn_astar.gif
â”‚   â”œâ”€â”€ ğŸ“¹ rrtstar.gif
â”‚   â”œâ”€â”€ ğŸ“¹ thetastar.gif
â”‚
â”œâ”€â”€ ğŸ“‚ test
â”‚   â”œâ”€â”€ ğŸ“„ test_astar.py
â”‚   â”œâ”€â”€ ğŸ“„ test_dstar.py
â”‚   â”œâ”€â”€ ğŸ“„ test_hybrid_dqn_a_star.py
â”‚   â”œâ”€â”€ ğŸ“„ test_rrt_star.py
â”‚   â”œâ”€â”€ ğŸ“„ test_theta_star.py
â”‚
â”œâ”€â”€ ğŸ“„ .gitignore
â”œâ”€â”€ ğŸ“„ LICENSE
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“„ requirements.txt
â”œâ”€â”€ ğŸ“„ setup.py
â”œâ”€â”€ ğŸ“‚ .github

```

---

## âš™ï¸ Installation
To run the algorithms, install the necessary dependencies:
```sh
pip install -r requirements.txt
pip install -e .

```

---

## ğŸš€ Usage
Each algorithm can be executed independently. Example usage:
```sh
python A_Star/a_star_algorithm.py
            or
pytest -v --verbose
```
Modify the scripts as needed to test different environments or configurations.

---

## ğŸ“Š Project Overview
The project contains several advanced path planning techniques, including:
### ğŸ”¹ **A\* Algorithm**
A classic grid-based path planning method that computes the optimal path using an 8-connected graph and a Euclidean distance heuristic.  
<img src="media/astar.gif" width="300" height="300" alt="A* Algorithm">

### ğŸ”¹ **Bidirectional A\***
An enhanced version of A\* that simultaneously searches from the start and goal, potentially reducing the search time.  
<img src="media/astar_bidirectional.gif" width="300" height="300" alt="Bidirectional A* Algorithm">

### ğŸ”¹ **D\* Algorithm**
A dynamic path planning algorithm that efficiently updates the optimal path in response to changes in the environment.  
<img src="media/dstar.gif" width="300" height="300" alt="D* Algorithm">

### ğŸ”¹ **RRT\* Algorithm**
A rapidly exploring random tree (RRT) is an algorithm designed to efficiently search nonconvex, high-dimensional spaces by randomly building a space-filling tree.  
<img src="media/rrtstar.gif" width="300" height="300" alt="D* Algorithm">

### ğŸ”¹ **Theta\* Algorithm**
An any-angle variant of A\* that uses line-of-sight checks to "shortcut" unnecessary nodes, producing smoother and more direct paths.  
<img src="media/thetastar.gif" width="300" height="300" alt="Theta* Algorithm">

### ğŸ”¹ **Advanced AI/ML (DQN-Based) Path Planning**
An implementation leveraging deep reinforcement learning (DQN) to learn an optimal navigation policy.  
<img src="media/dqn_astar.gif" width="300" height="300" alt="DQN-A* Algorithm">

---

## ğŸ¥ Visualization
Pathfinding results can be visualized using the generated `.gif` files in the `media` directory.

---

# **ğŸ“Š Performance Metrics Overview**

This table provides a performance comparison of various path-planning algorithms implemented in this project.


| **Algorithm**         | **Execution Time (s)** | **Path Length** | **Steps Taken** | **Direction Changes** | **Optimality**       | **Computational Efficiency** | **Scalability** | **Adaptability to Dynamic Environments** | **Best Use Cases**                                                                 |
|------------------------|------------------------|-----------------|-----------------|-----------------------|----------------------|------------------------------|-----------------|------------------------------------------|-----------------------------------------------------------------------------------|
| **A***                | 20.45 - 30.48 ğŸŸ¡       | 85.05 ğŸŸ¢        | 67 ğŸ”´            | 13 ğŸŸ¡                 | High ğŸŸ¢              | Low ğŸ”´                        | Low ğŸ”´          | Low ğŸ”´                                   | Structured static environments (e.g., warehouse automation)                       |
| **Bidirectional A***  | 4.20 - 5.46 ğŸŸ¢         | 96.77 ğŸŸ¡        | 87 ğŸ”´            | 7 ğŸŸ¢                  | Moderate ğŸŸ¡          | High ğŸŸ¢                       | Moderate ğŸŸ¡     | High ğŸŸ¢                                  | Dynamic environments with known obstacles                                         |
| **D***                | 20.50 - 22.11 ğŸŸ¡       | 85.05 ğŸŸ¢        | 67 ğŸ”´            | 13 ğŸŸ¡                 | High ğŸŸ¢              | Low ğŸ”´                        | Low ğŸ”´          | Moderate ğŸŸ¡                              | Real-time replanning in semi-dynamic environments                                 |
| **RRT***              | 8.03 - 39.19 ğŸŸ¡        | 104.69 - 113.35 ğŸ”´ | 22 - 24 ğŸŸ¢      | 21 - 22 ğŸ”´            | Low - Moderate ğŸŸ¡    | Moderate ğŸŸ¡                   | High ğŸŸ¢         | High ğŸŸ¢                                  | Exploration & high-dimensional navigation                                         |
| **Theta***            | 0.08 - 0.12 ğŸŸ¢         | 82.27 ğŸŸ¢        | 6 ğŸŸ¢             | 4 ğŸŸ¢                  | Very High ğŸŸ¢         | Very High ğŸŸ¢                  | High ğŸŸ¢         | Low ğŸ”´                                   | Precise trajectory planning & smooth motion                                       |
| **DQN-A***            | 0.01 ğŸŸ¢                | 85.05 ğŸŸ¢        | 67 ğŸ”´            | 13 ğŸŸ¡                 | High ğŸŸ¢              | Very High ğŸŸ¢                  | Very High ğŸŸ¢    | Very High ğŸŸ¢                             | AI-enhanced real-time obstacle avoidance                                          |

---

This comparison helps in selecting the appropriate algorithm based on the application requirements, balancing optimality, efficiency, and adaptability.

## ğŸ¨ **Legend**

- ğŸŸ¢ **Green**: Best performance in a category.
- ğŸŸ¡ **Yellow**: Moderate performance.
- ğŸ”´ **Red**: Lower performance or limitations.


## ğŸ¯ **Key Insights**

- âš¡ **Fastest Algorithms**: 
  - **DQN-A*** (0.01s) and **Theta*** (0.08 - 0.12s) are the fastest.
- ğŸ›¤ï¸ **Shortest Path**: 
  - **Theta*** achieves the shortest path length (82.27) with minimal direction changes (4).
- ğŸ”„ **Best for Dynamic Environments**: 
  - **Bidirectional A*** and **RRT*** excel in adaptability to dynamic environments.
- ğŸ¤– **AI-Enhanced Performance**: 
  - **DQN-A*** combines high optimality with very high computational efficiency and scalability.



## ğŸ¤ Contributing
Contributions are welcome! To contribute:
1. Fork the repository
2. Create a new branch (`git checkout -b feature-branch`)
3. Commit changes (`git commit -m "Add new feature"`)
4. Push to the branch (`git push origin feature-branch`)
5. Open a Pull Request

---

## ğŸ“œ License
This project is licensed under the **MIT License** - see the LICENSE file for details.

---

## ğŸ“š **Citation**

If you find this repository useful for your work, please consider citing it in your research or projects. Below are the citation details in **APA 7th edition** and **BibTeX** formats.

---

### **APA 7th Edition**

```plaintext
Gouda Shanbog, D. N. (2025). Path-Planning-for-Intelligent-Mobile-Robots (1.0.1). Zenodo. https://doi.org/10.5281/zenodo.14954689
```
- BibTeX
```
@software{gouda_shanbog_2025_14954689,
  author       = {Gouda Shanbog, Dada Nanjesha},
  title        = {Path-Planning-for-Intelligent-Mobile-Robots},
  month        = feb,
  year         = 2025,
  publisher    = {Zenodo},
  version      = {1.0.1},
  doi          = {10.5281/zenodo.14954689},
  url          = {https://doi.org/10.5281/zenodo.14954689},
}
```
---
## ğŸ“¬ Contact
For inquiries or collaborations, reach out via **GitHub Issues**.

---

ğŸ‰ **Happy Coding!** ğŸš€

